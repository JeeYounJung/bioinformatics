{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-027da61e09ea6982",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# BMI/CS 576 - HW6 - Fall 2023\n",
    "The objectives of this homework are to better understand\n",
    "\n",
    "* Gaussian mixture model-based clustering\n",
    "* Bottom-up hierarchical clustering\n",
    "* scoring Bayesian networks with model evidence\n",
    "* determining causal relationships\n",
    "\n",
    "## HW policies\n",
    "Before starting this homework, please read over the [homework policies](https://canvas.wisc.edu/courses/374201/modules/items/6356820) for this course.  In particular, note that homeworks are to be completed *individually* and plagiarism from any source (with the one exception noted below) will be considered **academic misconduct**.\n",
    "\n",
    "You are welcome to use any code from the weekly notebooks (including the official solutions) in your solutions to the HW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5835bba65cdd2ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PROBLEM 1: Gaussian mixture model-based clustering (25 points)\n",
    "\n",
    "Run the EM algorithm (either by hand or with your **own** code) for Gaussian mixture model-based\n",
    "clustering on the the following set of one-dimensional points: $X = (x_1,x_2,x_3,x_4,x_5) = (-5,-2,0,3,9)$ for **two** iterations.\n",
    "Let $k=2$, the initial cluster means be $\\mu_1 = -4$ and $\\mu_2 = 3$,\n",
    "the initial cluster prior probabilities be $P_1 = P_2 = 0.5$, and the\n",
    "variances be $\\sigma^2_1 = \\sigma^2_2 = 9$.  You should treat the variances as fixed\n",
    "parameters that are not updated during EM.  After each iteration, show \n",
    "\n",
    "**(i)** the probabilities of each point being assigned to each cluster\n",
    "\n",
    "**(ii)** the cluster that is most probable for each point\n",
    "\n",
    "**(iii)** the updated cluster means, and \n",
    "\n",
    "**(iv)** the updated cluster prior probabilities. \n",
    "\n",
    "*If you run the algorithm via code, you must present the output in a nicely formatted manner.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p1",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### BEGIN SOLUTION TEMPLATE=solution to problem 1\n",
    "![p1_solution](em_solution.png)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6827493ae90df9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PROBLEM 2: Bottom-up hierarchical clustering (25 points)\n",
    "\n",
    "Suppose we wish to compute a hierarchical clustering of the following one-dimensional points $(A, B, C, D, E) = (0, 6, 11, 15, 18)$.  Below is the Euclidean distance matrix for these points.\n",
    "\n",
    "|       | A | B  |  C | D  | E  |\n",
    "|-------|---|----|----|----|----|\n",
    "| **A** | 0 | 6  | 11 | 15 | 18 |\n",
    "| **B** | 6 | 0  |  5 | 9  | 12 |\n",
    "| **C** | 11| 5  |  0 | 4  | 7  |\n",
    "| **D** | 15| 9  |  4 | 0  | 3  |\n",
    "| **E** |18 | 12 |  7 | 3  | 0  |\n",
    "\n",
    "**(a)** Compute a hierarchical clustering of these points using *single link*.  Give the intermediate tree and distance matrix after each iteration.\n",
    "\n",
    "**(b)** Compute a hierarchical clustering of these points using *complete link*.  Give the intermediate tree and distance matrix after each iteration.\n",
    "\n",
    "**(b)** Compute a hierarchical clustering of these points using *average link*.  Give the intermediate tree and distance matrix after each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p2",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "### BEGIN SOLUTION TEMPLATE=solution to problem 2\n",
    "\n",
    "![p2_solution](p2_solution.png)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3efc15f74bf1d298",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## PROBLEM 3 (20 POINTS)\n",
    "\n",
    "Consider the Bayesian network shown below\n",
    "\n",
    "![p3 network](p3_network.png)\n",
    "\n",
    "The model evidence formula for this network is\n",
    "\n",
    "$$\\log P(D|G) = -\\left(\\log(n+1) + \\log {n \\choose n_{1,0}} + \\log(n+1) + \\log {n \\choose n_{3,0}} + \\sum_{a \\in \\{0, 1\\}} \\left(\\log (n_{1,a} + 1) + \\log {n_{1,a} \\choose n_{2,a,0} } \\right)  \\right)$$\n",
    "\n",
    "where the data dependent values (the \"sufficient statistics\") are defined as follows:\n",
    "\n",
    "$$n_{1,a} = |\\{i: x_{1,i} = a\\}|$$\n",
    "$$n_{3,a} = |\\{i: x_{3,i} = a\\}|$$\n",
    "$$n_{2,a,c} = |\\{i: x_{1,i} = a, x_{2,i} = c\\}|$$\n",
    "$$n = {|\\{i\\}|}$$\n",
    "\n",
    "In this problem we will use the same dataset as in notebook 24 (provided as the file [`data.txt`](data.txt) and read in with the cell below).\n",
    "\n",
    "**(a)** For this dataset, compute the values of the sufficient statistics (defined above) for the model evidence of this network.  Show your code for computing these values.\n",
    "\n",
    "**(b)** Given your values from (a), compute the model evidence (defined above) of this network.  Show your work.\n",
    "\n",
    "\n",
    "**(c)** Compare your answer from (b) to the model evidence computed for the network in notebook 24.  Which network structure is a better fit for this dataset?  Justify your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data set as a list of tuples \n",
    "# (each tuple is one joint observation of the three variables)\n",
    "data = [tuple(map(int, line.split())) for line in open(\"data.txt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p3",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### BEGIN SOLUTION TEMPLATE=solution to problem 3\n",
    "\n",
    "**(a)** Computed with the code below.\n",
    "$$\\begin{eqnarray}\n",
    "n & = & 1000 \\\\\n",
    "n_{1,0} & = & 733 \\\\\n",
    "n_{1,1} & = & 267 \\\\\n",
    "n_{3,0} & = & 734 \\\\\n",
    "n_{2,0,0} & = & 542 \\\\\n",
    "n_{2,1,0} & = & 196\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "**(b)** Computed with the code below\n",
    "$$\\log P(D|G) \\approx -1747$$\n",
    "\n",
    "**(c)** The model evidence of this network is less than that from notebook 24 (which was $\\approx -1579$), and thus  the network in this problem is a worse fit for the given dataset.\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION TEMPLATE=any code used for your solution to problem 3\n",
    "import bayesian_network\n",
    "import itertools\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "def logbinom(n, k):\n",
    "    \"\"\"The natural logarithm of the binomial coefficient (n choose k)\"\"\"\n",
    "    return math.lgamma(n + 1) - math.lgamma(k + 1) - math.lgamma(n - k + 1)\n",
    "\n",
    "def sufficient_statistics(bn, data):\n",
    "    ss = []\n",
    "    for i in range(bn.num_vertices()):\n",
    "        parent_possible_values = [bn.possible_values[j] for j in bn.parents(i)]\n",
    "        vertex_ss = {parent_vals: [0] * len(bn.possible_values[i])\n",
    "                     for parent_vals in itertools.product(*parent_possible_values)}\n",
    "        ss.append(vertex_ss)\n",
    "\n",
    "    for values in data:\n",
    "        encoded_values = bn.encode_values(values)\n",
    "        for i, value in enumerate(encoded_values):\n",
    "            parent_values = tuple(encoded_values[j] for j in bn.parents(i))\n",
    "            ss[i][parent_values][value] += 1\n",
    "\n",
    "    return ss\n",
    "\n",
    "def model_evidence(bn, data):\n",
    "    \"\"\"assumes binary random variables\"\"\"\n",
    "    ss = sufficient_statistics(bn, data)\n",
    "    me = 0\n",
    "    for i, vertex_ss in enumerate(ss):\n",
    "        for count_vector in vertex_ss.values():\n",
    "            total_counts = sum(count_vector)\n",
    "            me -= (math.log(total_counts + 1) + logbinom(total_counts, count_vector[0]))\n",
    "    return me\n",
    "\n",
    "random_variables = [\"x1\", \"x2\", \"x3\"]\n",
    "g = bayesian_network.BayesianNetwork(random_variables)\n",
    "g.set_cpd(\"x1\",\n",
    "          [], [0, 1],\n",
    "          {(): [0.75, 0.25]})\n",
    "g.set_cpd(\"x2\",\n",
    "          [\"x1\"], [0, 1],\n",
    "          {(0,): [0.9, 0.1],\n",
    "           (1,): [0.3, 0.7]})\n",
    "g.set_cpd(\"x3\",\n",
    "          [], [0, 1],\n",
    "          {(): [0.75, 0.25]})\n",
    "\n",
    "log_prob_data_given_graph = model_evidence(g, data)\n",
    "pprint.pprint(sufficient_statistics(g, data), width=20)\n",
    "print(\"n =\", len(data))\n",
    "print(log_prob_data_given_graph)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p4_description",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## PROBLEM 4 (30 POINTS)\n",
    "\n",
    "Suppose we wish to construct a Bayesian network representing the gene regulatory network for two genes, $X$ and $Y$.\n",
    "We are given data from 80 independent observational experiments in which the expression levels of the two genes are measured.  The expression level of each gene is measured as either \"low\" (L) \"medium\" (M), or \"high\" (H).  Below is a table summarizing the number of times (count) each configuration of gene expression status was observed in these experiments.\n",
    "\n",
    "\n",
    "| X | Y | count |\n",
    "|---|---|-------|\n",
    "| L | L |   4   |\n",
    "| L | M |   8   |\n",
    "| L | H |  16   |\n",
    "| M | L |   4   |\n",
    "| M | M |   6   |\n",
    "| M | H |   2   |\n",
    "| H | L |  32   |\n",
    "| H | M |   6   |\n",
    "| H | H |   2   |\n",
    "\n",
    "**(a)** Give a table specifying the joint probability distribution, $P(X, Y)$, that we would estimate from these data.\n",
    "\n",
    "**(b)** Compute the mutual information (use the natural log) between $X$ and $Y$ given your table from (a).  Show your work.  Assuming the estimated distribution in (a) is the true distribution, are $X$ and $Y$ independent of each other?  Justify your answer.\n",
    "\n",
    "**(c)** Suppose we use the Bayesian network structure below.  Give the CPDs for $X$ and $Y$ such that the joint distribution represented by the network is the same as that estimated in (a).\n",
    "\n",
    "![p4 network c](p4_network_c.png)\n",
    "\n",
    "**(d)** Suppose we use the alternative Bayesian network structure below.  Give the CPDs for $X$ and $Y$ such that the joint distribution represented by the network is the same as that estimated in (a).\n",
    "\n",
    "![p4 network d](p4_network_d.png)\n",
    "\n",
    "**(e)** You are now given data from an intervention experiment in which gene $Y$ is forced to be \"low\" through an intervention (e.g., with a [small interfering RNA](https://en.wikipedia.org/wiki/Small_interfering_RNA) targeting $Y$).  This experiment is repeated 100 times, giving the following counts for the measurements of gene $X$.\n",
    "\n",
    "| X | count |\n",
    "|---|-------|\n",
    "| L |  10   |\n",
    "| M |  10   |\n",
    "| H |  80   |\n",
    "\n",
    "Which of the two networks considered in (c) and (d) is more likely to better model the true causal relationships in the gene regulatory network?  Justify your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p4",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "### BEGIN SOLUTION TEMPLATE=solution to problem 4\n",
    "\n",
    "**(a)** \n",
    "\n",
    "| X | Y | P(X, Y) |\n",
    "|---|---|-------|\n",
    "| L | L | 0.05 |\n",
    "| L | M | 0.10 |\n",
    "| L | H | 0.20 |\n",
    "| M | L | 0.05 |\n",
    "| M | M | 0.075 |\n",
    "| M | H | 0.025 |\n",
    "| H | L | 0.40 |\n",
    "| H | M | 0.075 |\n",
    "| H | H | 0.025 |\n",
    "\n",
    "**(b)** \n",
    "\n",
    "| X | Y | P(X, Y) | P(X) | P(Y) | P(X,Y) log(P(X,Y)/(P(X)P(Y))) |\n",
    "|---|---|---------|------|------|-------------------------------|\n",
    "| L | L | 0.05 | 0.35 | 0.50 | -0.0626 |\n",
    "| L | M | 0.10 | 0.35 | 0.25 | +0.0134 |\n",
    "| L | H | 0.20 | 0.35 | 0.25 | +0.1650 |\n",
    "| M | L | 0.05 | 0.15 | 0.50 | -0.0203 |\n",
    "| M | M | 0.075 | 0.15 | 0.25 | +0.0520 |\n",
    "| M | H | 0.025 | 0.15 | 0.25 | -0.0101 |\n",
    "| H | L | 0.40 | 0.50 | 0.50 | +0.1880 |\n",
    "| H | M | 0.075 | 0.50 | 0.25 | -0.0383 |\n",
    "| H | H | 0.025 | 0.50 | 0.25 | -0.0402 |\n",
    "\n",
    "\n",
    "$$I(X,Y) \\approx 0.247$$\n",
    "\n",
    "(with log base 2, $I(X,Y)=0.356$, and with log base 10, $I(X,Y)=0.107$ )\n",
    "\n",
    "\n",
    "**(c)** \n",
    "\n",
    "P(X)\n",
    "\n",
    "| X | P(X) |\n",
    "|---|------|\n",
    "| L | 0.35 |\n",
    "| M | 0.15 |\n",
    "| H | 0.50 |\n",
    "\n",
    "P(Y|X)\n",
    "\n",
    "| X | P(Y=L\\|X) | P(Y=M\\|X) | P(Y=H\\|X) |\n",
    "|---|----------|----------|----------|\n",
    "| L | 0.143 | 0.286 | 0.571 | \n",
    "| M | 0.333 | 0.50 | 0.167 | \n",
    "| H | 0.80 | 0.15 | 0.05 | \n",
    "\n",
    "\n",
    "**(d)** \n",
    "\n",
    "P(Y)\n",
    "\n",
    "| Y | P(Y) |\n",
    "|---|------|\n",
    "| L | 0.50 |\n",
    "| M | 0.25 |\n",
    "| H | 0.25 |\n",
    "\n",
    "P(X|Y)\n",
    "\n",
    "| Y | P(X=L\\|Y) | P(X=M\\|Y) | P(X=H\\|Y) |\n",
    "|---|----------|----------|----------|\n",
    "| L | 0.10 | 0.10 | 0.80 | \n",
    "| M | 0.40 | 0.30 | 0.30 | \n",
    "| H | 0.80 | 0.10 | 0.10 | \n",
    "\n",
    "**(e)** The distribution of X in this intervention data is \n",
    "\n",
    "| X |     P(X)       |\n",
    "|---|----------------|\n",
    "| L |  10/100 = 0.1  |\n",
    "| M |  10/100 = 0.1  |\n",
    "| H |  80/100 = 0.8  |\n",
    "\n",
    "This distribution is markedly different from the marginal distribution of X in the observational data and identical to the conditional distribution $P(X | Y = L)$ found in part (d).  This suggests that Y is causal of X and that the Bayesian network from part (d) is the better causal model.  Had the opposite been the case (X causal of Y), we would have expected this intervention distribution of X to be similar to that in the observational data.\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
